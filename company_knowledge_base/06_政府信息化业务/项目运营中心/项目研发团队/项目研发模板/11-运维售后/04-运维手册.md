# 知识库系统运维手册

## 文档信息
- **文档版本**: v1.0
- **创建日期**: 2024-01-15
- **最后更新**: 2024-01-15
- **负责人**: 运维工程师
- **审核人**: 技术负责人

## 系统概述

### 系统架构
知识库系统采用微服务架构，主要包含以下组件：
- **前端服务**: React应用，提供用户界面
- **后端API**: Flask应用，提供RESTful API
- **图数据库**: NebulaGraph，存储知识图谱数据
- **缓存服务**: Redis，提供缓存和会话存储
- **文件存储**: MinIO，存储文件和媒体资源
- **监控系统**: Prometheus + Grafana，系统监控
- **日志系统**: ELK Stack，日志收集和分析

### 服务清单
| 服务名称 | 端口 | 协议 | 说明 |
|----------|------|------|------|
| Frontend | 3000 | HTTP | React前端应用 |
| Backend API | 5000 | HTTP | Flask后端API |
| NebulaGraph | 9669 | TCP | 图数据库查询端口 |
| Redis | 6379 | TCP | 缓存服务 |
| MinIO | 9000 | HTTP | 对象存储服务 |
| Prometheus | 9090 | HTTP | 监控数据收集 |
| Grafana | 3001 | HTTP | 监控数据可视化 |
| Nginx | 80/443 | HTTP/HTTPS | 反向代理和负载均衡 |

## 日常运维

### 服务状态检查

#### 系统服务检查
```bash
#!/bin/bash
# check_services.sh - 服务状态检查脚本

echo "=== 知识库系统服务状态检查 ==="
echo "检查时间: $(date)"
echo

# 检查Docker容器状态
echo "1. Docker容器状态:"
docker-compose ps

echo -e "\n2. 服务端口检查:"
# 检查关键端口
ports=(3000 5000 9669 6379 9000 9090 3001 80 443)
for port in "${ports[@]}"; do
    if netstat -tlnp | grep ":$port " > /dev/null; then
        echo "✓ 端口 $port 正常监听"
    else
        echo "✗ 端口 $port 未监听"
    fi
done

echo -e "\n3. 服务健康检查:"
# 前端健康检查
if curl -s http://localhost:3000 > /dev/null; then
    echo "✓ 前端服务正常"
else
    echo "✗ 前端服务异常"
fi

# 后端API健康检查
if curl -s http://localhost:5000/health > /dev/null; then
    echo "✓ 后端API服务正常"
else
    echo "✗ 后端API服务异常"
fi

# NebulaGraph健康检查
if docker exec nebula-graphd nebula-console -e "SHOW HOSTS" > /dev/null 2>&1; then
    echo "✓ NebulaGraph服务正常"
else
    echo "✗ NebulaGraph服务异常"
fi

# Redis健康检查
if redis-cli ping | grep PONG > /dev/null; then
    echo "✓ Redis服务正常"
else
    echo "✗ Redis服务异常"
fi

echo -e "\n4. 系统资源使用:"
echo "CPU使用率: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')"
echo "内存使用率: $(free | grep Mem | awk '{printf("%.1f%%", $3/$2 * 100.0)}')"
echo "磁盘使用率: $(df -h / | awk 'NR==2{printf "%s", $5}')"
```

#### 数据库状态检查
```bash
#!/bin/bash
# check_database.sh - 数据库状态检查

echo "=== 数据库状态检查 ==="

# NebulaGraph状态检查
echo "1. NebulaGraph集群状态:"
docker exec nebula-graphd nebula-console -e "SHOW HOSTS"

echo -e "\n2. NebulaGraph空间信息:"
docker exec nebula-graphd nebula-console -e "SHOW SPACES"

echo -e "\n3. 数据统计:"
docker exec nebula-graphd nebula-console -e "USE knowledge_base; SHOW STATS"

# Redis状态检查
echo -e "\n4. Redis状态:"
redis-cli info server | grep redis_version
redis-cli info memory | grep used_memory_human
redis-cli info stats | grep total_commands_processed

echo -e "\n5. Redis键统计:"
redis-cli info keyspace
```

### 日志管理

#### 日志文件位置
```bash
# 应用日志
/var/log/knowledge-base/
├── frontend/
│   ├── access.log      # 前端访问日志
│   └── error.log       # 前端错误日志
├── backend/
│   ├── app.log         # 应用日志
│   ├── error.log       # 错误日志
│   └── access.log      # API访问日志
├── nginx/
│   ├── access.log      # Nginx访问日志
│   └── error.log       # Nginx错误日志
└── system/
    ├── nebula/         # NebulaGraph日志
    ├── redis/          # Redis日志
    └── docker/         # Docker容器日志
```

#### 日志查看命令
```bash
# 查看实时日志
tail -f /var/log/knowledge-base/backend/app.log

# 查看错误日志
grep "ERROR" /var/log/knowledge-base/backend/app.log | tail -20

# 查看Docker容器日志
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f nebula-graphd

# 查看系统日志
journalctl -u knowledge-base -f
```

#### 日志轮转配置
```bash
# /etc/logrotate.d/knowledge-base
/var/log/knowledge-base/*/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 knowledge-base knowledge-base
    postrotate
        systemctl reload nginx
        docker-compose restart backend
    endscript
}
```

### 备份管理

#### 自动备份脚本
```bash
#!/bin/bash
# backup.sh - 自动备份脚本

BACKUP_DIR="/backup/knowledge-base"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR/{database,files,config}

echo "开始备份 - $(date)"

# 1. 备份NebulaGraph数据
echo "备份NebulaGraph数据..."
docker exec nebula-graphd nebula-dump \
    --host=localhost --port=9669 \
    --user=root --password=nebula \
    --space=knowledge_base \
    --output=/tmp/nebula_backup_$DATE.sql

docker cp nebula-graphd:/tmp/nebula_backup_$DATE.sql $BACKUP_DIR/database/
gzip $BACKUP_DIR/database/nebula_backup_$DATE.sql

# 2. 备份Redis数据
echo "备份Redis数据..."
redis-cli --rdb $BACKUP_DIR/database/redis_backup_$DATE.rdb

# 3. 备份应用文件
echo "备份应用文件..."
tar -czf $BACKUP_DIR/files/uploads_$DATE.tar.gz /opt/knowledge-base/uploads
tar -czf $BACKUP_DIR/files/logs_$DATE.tar.gz /var/log/knowledge-base

# 4. 备份配置文件
echo "备份配置文件..."
tar -czf $BACKUP_DIR/config/config_$DATE.tar.gz \
    /opt/knowledge-base/.env \
    /opt/knowledge-base/docker-compose.yml \
    /etc/nginx/sites-available/knowledge-base

# 5. 清理旧备份
echo "清理旧备份..."
find $BACKUP_DIR -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "*.rdb" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

echo "备份完成 - $(date)"

# 6. 备份验证
echo "备份验证..."
ls -lh $BACKUP_DIR/database/nebula_backup_$DATE.sql.gz
ls -lh $BACKUP_DIR/database/redis_backup_$DATE.rdb
ls -lh $BACKUP_DIR/files/uploads_$DATE.tar.gz
ls -lh $BACKUP_DIR/config/config_$DATE.tar.gz
```

#### 数据恢复脚本
```bash
#!/bin/bash
# restore.sh - 数据恢复脚本

BACKUP_DIR="/backup/knowledge-base"
BACKUP_DATE=$1

if [ -z "$BACKUP_DATE" ]; then
    echo "使用方法: $0 <备份日期>"
    echo "示例: $0 20240115_140000"
    exit 1
fi

echo "开始恢复数据 - $(date)"
echo "恢复备份: $BACKUP_DATE"

# 1. 停止服务
echo "停止服务..."
docker-compose down

# 2. 恢复NebulaGraph数据
echo "恢复NebulaGraph数据..."
gunzip -c $BACKUP_DIR/database/nebula_backup_$BACKUP_DATE.sql.gz > /tmp/restore.sql
docker-compose up -d nebula-graphd nebula-metad nebula-storaged
sleep 30
docker exec nebula-graphd nebula-console -f /tmp/restore.sql

# 3. 恢复Redis数据
echo "恢复Redis数据..."
cp $BACKUP_DIR/database/redis_backup_$BACKUP_DATE.rdb /var/lib/redis/dump.rdb
chown redis:redis /var/lib/redis/dump.rdb

# 4. 恢复应用文件
echo "恢复应用文件..."
tar -xzf $BACKUP_DIR/files/uploads_$BACKUP_DATE.tar.gz -C /

# 5. 恢复配置文件
echo "恢复配置文件..."
tar -xzf $BACKUP_DIR/config/config_$BACKUP_DATE.tar.gz -C /

# 6. 启动服务
echo "启动服务..."
docker-compose up -d

echo "数据恢复完成 - $(date)"
```

## 监控告警

### Prometheus监控配置

#### 监控指标
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

scrape_configs:
  # 应用监控
  - job_name: 'knowledge-base-backend'
    static_configs:
      - targets: ['backend:5000']
    metrics_path: '/metrics'
    scrape_interval: 30s

  # 系统监控
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # 数据库监控
  - job_name: 'nebula-exporter'
    static_configs:
      - targets: ['nebula-exporter:9200']

  - job_name: 'redis-exporter'
    static_configs:
      - targets: ['redis-exporter:9121']

alertmanager:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

#### 告警规则
```yaml
# alert_rules.yml
groups:
  - name: knowledge-base-alerts
    rules:
      # 服务可用性告警
      - alert: ServiceDown
        expr: up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "服务 {{ $labels.job }} 不可用"
          description: "服务 {{ $labels.job }} 已经停止响应超过1分钟"

      # 高CPU使用率告警
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "CPU使用率过高"
          description: "实例 {{ $labels.instance }} CPU使用率超过80%"

      # 高内存使用率告警
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "内存使用率过高"
          description: "实例 {{ $labels.instance }} 内存使用率超过85%"

      # 磁盘空间告警
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "磁盘空间不足"
          description: "实例 {{ $labels.instance }} 磁盘剩余空间少于10%"

      # API响应时间告警
      - alert: HighAPIResponseTime
        expr: histogram_quantile(0.95, rate(flask_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "API响应时间过长"
          description: "95%的API请求响应时间超过2秒"

      # 数据库连接告警
      - alert: DatabaseConnectionHigh
        expr: nebula_graph_connections_active / nebula_graph_connections_max * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "数据库连接数过高"
          description: "NebulaGraph活跃连接数超过最大连接数的80%"
```

### Grafana仪表板

#### 系统概览仪表板
- **服务状态**: 显示所有服务的运行状态
- **系统资源**: CPU、内存、磁盘、网络使用情况
- **请求统计**: API请求量、响应时间、错误率
- **用户活跃度**: 在线用户数、活跃用户数

#### 应用性能仪表板
- **API性能**: 各接口的响应时间和调用量
- **数据库性能**: 查询响应时间、连接数、缓存命中率
- **业务指标**: 知识创建量、搜索量、用户增长

### 告警通知配置

#### AlertManager配置
```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    email_configs:
      - to: 'ops-team@example.com'
        subject: '知识库系统告警: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          告警: {{ .Annotations.summary }}
          描述: {{ .Annotations.description }}
          时间: {{ .StartsAt }}
          {{ end }}
    
    webhook_configs:
      - url: 'http://webhook-server:9093/webhook'
        send_resolved: true
```

## 故障处理

### 常见故障及解决方案

#### 1. 服务无法启动
**症状**: 服务启动失败或启动后立即退出

**排查步骤**:
```bash
# 1. 检查服务状态
docker-compose ps
systemctl status knowledge-base

# 2. 查看错误日志
docker-compose logs backend
journalctl -u knowledge-base -n 50

# 3. 检查配置文件
python -c "import config; print(config.Config.__dict__)"

# 4. 检查端口占用
netstat -tlnp | grep :5000
```

**解决方案**:
- 检查配置文件语法错误
- 确认端口未被占用
- 检查依赖服务是否正常运行
- 验证环境变量配置

#### 2. 数据库连接失败
**症状**: 应用无法连接到NebulaGraph或Redis

**排查步骤**:
```bash
# 1. 测试数据库连接
nebula-console -addr localhost -port 9669 -u root -p nebula
redis-cli -h localhost -p 6379 ping

# 2. 检查数据库服务状态
docker-compose ps nebula-graphd
docker-compose ps redis

# 3. 检查网络连通性
telnet localhost 9669
telnet localhost 6379
```

**解决方案**:
- 重启数据库服务
- 检查数据库配置参数
- 验证网络连接和防火墙设置
- 检查数据库用户权限

#### 3. 性能问题
**症状**: 系统响应缓慢，用户体验差

**排查步骤**:
```bash
# 1. 检查系统资源
top
htop
iotop
free -h
df -h

# 2. 检查应用性能
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:5000/api/health

# 3. 检查数据库性能
docker exec nebula-graphd nebula-console -e "SHOW STATS"
redis-cli info stats
```

**解决方案**:
- 增加系统资源（CPU、内存）
- 优化数据库查询
- 启用缓存机制
- 调整应用配置参数

#### 4. 磁盘空间不足
**症状**: 系统提示磁盘空间不足

**排查步骤**:
```bash
# 1. 检查磁盘使用情况
df -h
du -sh /var/log/knowledge-base/*
du -sh /opt/knowledge-base/uploads/*

# 2. 查找大文件
find /var/log -size +100M -type f
find /opt/knowledge-base -size +100M -type f
```

**解决方案**:
```bash
# 1. 清理日志文件
find /var/log/knowledge-base -name "*.log" -mtime +7 -delete
logrotate -f /etc/logrotate.d/knowledge-base

# 2. 清理临时文件
rm -rf /tmp/knowledge-base-*
docker system prune -f

# 3. 压缩旧文件
gzip /var/log/knowledge-base/*/*.log.1
```

### 应急响应流程

#### 故障等级定义
| 等级 | 描述 | 响应时间 | 解决时间 |
|------|------|----------|----------|
| P0 - 紧急 | 系统完全不可用 | 15分钟 | 2小时 |
| P1 - 高 | 核心功能不可用 | 30分钟 | 4小时 |
| P2 - 中 | 部分功能异常 | 2小时 | 1天 |
| P3 - 低 | 轻微问题 | 1天 | 3天 |

#### 应急联系人
| 角色 | 姓名 | 电话 | 邮箱 | 备注 |
|------|------|------|------|------|
| 运维负责人 | [姓名] | [电话] | [邮箱] | 7x24小时 |
| 技术负责人 | [姓名] | [电话] | [邮箱] | 工作时间 |
| 开发负责人 | [姓名] | [电话] | [邮箱] | 工作时间 |
| 业务负责人 | [姓名] | [电话] | [邮箱] | 工作时间 |

#### 故障处理流程
1. **故障发现**: 监控告警或用户反馈
2. **初步评估**: 确定故障等级和影响范围
3. **应急响应**: 通知相关人员，启动应急预案
4. **问题定位**: 分析日志，定位根本原因
5. **临时修复**: 实施临时解决方案，恢复服务
6. **根本修复**: 实施永久解决方案
7. **验证测试**: 确认问题已解决
8. **总结报告**: 编写故障报告，改进预防措施

## 性能优化

### 系统性能调优

#### 操作系统优化
```bash
# 1. 内核参数优化
cat >> /etc/sysctl.conf << EOF
# 网络优化
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_max_tw_buckets = 5000

# 内存优化
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5

# 文件系统优化
fs.file-max = 65535
fs.nr_open = 1048576
EOF

sysctl -p

# 2. 文件描述符限制
cat >> /etc/security/limits.conf << EOF
* soft nofile 65535
* hard nofile 65535
* soft nproc 65535
* hard nproc 65535
EOF
```

#### 应用性能优化
```python
# gunicorn配置优化
# gunicorn.conf.py
import multiprocessing

bind = "0.0.0.0:5000"
workers = multiprocessing.cpu_count() * 2 + 1
worker_class = "gevent"
worker_connections = 1000
max_requests = 1000
max_requests_jitter = 100
preload_app = True
timeout = 30
keepalive = 2

# 日志配置
accesslog = "/var/log/knowledge-base/gunicorn_access.log"
errorlog = "/var/log/knowledge-base/gunicorn_error.log"
loglevel = "info"
```

#### 数据库性能优化
```bash
# NebulaGraph配置优化
# nebula-graphd.conf
--enable_partitions_in_index=true
--rocksdb_block_cache=2048MB
--rocksdb_row_cache=512MB
--rocksdb_wal_size_limit=1024MB
--heartbeat_interval_secs=3
--session_idle_timeout_secs=28800

# Redis配置优化
# redis.conf
maxmemory 4gb
maxmemory-policy allkeys-lru
tcp-keepalive 300
timeout 300
save 900 1
save 300 10
save 60 10000
```

### 缓存策略

#### 应用层缓存
```python
# Flask缓存配置
from flask_caching import Cache

cache = Cache()
cache.init_app(app, config={
    'CACHE_TYPE': 'redis',
    'CACHE_REDIS_HOST': 'localhost',
    'CACHE_REDIS_PORT': 6379,
    'CACHE_REDIS_DB': 1,
    'CACHE_DEFAULT_TIMEOUT': 300
})

# 缓存装饰器使用
@cache.cached(timeout=300, key_prefix='knowledge_list')
def get_knowledge_list():
    # 获取知识列表的逻辑
    pass

@cache.memoize(timeout=600)
def get_knowledge_by_id(knowledge_id):
    # 根据ID获取知识的逻辑
    pass
```

#### CDN配置
```nginx
# Nginx CDN配置
location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
    add_header Vary Accept-Encoding;
    
    # 启用gzip压缩
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/css application/javascript image/svg+xml;
}

# API缓存
location /api/public/ {
    proxy_pass http://backend;
    proxy_cache api_cache;
    proxy_cache_valid 200 5m;
    proxy_cache_key "$scheme$request_method$host$request_uri";
    add_header X-Cache-Status $upstream_cache_status;
}
```

## 安全管理

### 安全检查清单

#### 系统安全
- [ ] 操作系统补丁更新
- [ ] 防火墙规则配置
- [ ] SSH密钥认证
- [ ] 用户权限最小化
- [ ] 审计日志启用

#### 应用安全
- [ ] HTTPS证书有效
- [ ] API认证机制
- [ ] 输入数据验证
- [ ] SQL注入防护
- [ ] XSS攻击防护

#### 数据安全
- [ ] 数据库访问控制
- [ ] 敏感数据加密
- [ ] 备份数据加密
- [ ] 数据传输加密
- [ ] 数据访问审计

### 安全监控

#### 入侵检测
```bash
# 安装fail2ban
sudo apt-get install fail2ban

# 配置fail2ban
cat > /etc/fail2ban/jail.local << EOF
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5

[sshd]
enabled = true
port = ssh
logpath = /var/log/auth.log

[nginx-http-auth]
enabled = true
port = http,https
logpath = /var/log/nginx/error.log

[knowledge-base-api]
enabled = true
port = 5000
logpath = /var/log/knowledge-base/backend/error.log
filter = knowledge-base-api
maxretry = 10
EOF
```

#### 漏洞扫描
```bash
#!/bin/bash
# security_scan.sh - 安全扫描脚本

echo "=== 安全扫描报告 ==="
echo "扫描时间: $(date)"

# 1. 系统漏洞扫描
echo -e "\n1. 系统安全更新检查:"
apt list --upgradable 2>/dev/null | grep -i security

# 2. 端口扫描
echo -e "\n2. 开放端口检查:"
nmap -sT localhost

# 3. 文件权限检查
echo -e "\n3. 敏感文件权限检查:"
find /opt/knowledge-base -name "*.env" -exec ls -la {} \;
find /etc/ssl -name "*.key" -exec ls -la {} \;

# 4. 用户权限检查
echo -e "\n4. 用户权限检查:"
awk -F: '$3 == 0 {print $1}' /etc/passwd
grep -E '^sudo|^admin|^wheel' /etc/group

# 5. 日志异常检查
echo -e "\n5. 安全日志检查:"
grep -i "failed\|error\|attack" /var/log/auth.log | tail -10
```

## 容量规划

### 性能基准测试

#### 负载测试脚本
```bash
#!/bin/bash
# load_test.sh - 负载测试脚本

# 测试参数
BASE_URL="http://localhost:5000"
CONCURRENT_USERS=100
TEST_DURATION=300  # 5分钟

echo "开始负载测试..."
echo "目标URL: $BASE_URL"
echo "并发用户: $CONCURRENT_USERS"
echo "测试时长: $TEST_DURATION 秒"

# 使用Apache Bench进行测试
ab -n 10000 -c $CONCURRENT_USERS -t $TEST_DURATION \
   -H "Content-Type: application/json" \
   -p test_data.json \
   $BASE_URL/api/knowledge/search

# 使用wrk进行测试
wrk -t12 -c$CONCURRENT_USERS -d${TEST_DURATION}s \
    --script=load_test.lua \
    $BASE_URL/api/knowledge/list

echo "负载测试完成"
```

#### 容量评估
```python
# capacity_planning.py - 容量规划计算

class CapacityPlanner:
    def __init__(self):
        self.current_users = 1000
        self.growth_rate = 0.2  # 20% 年增长率
        self.peak_factor = 3    # 峰值倍数
        
    def calculate_future_capacity(self, years=3):
        """计算未来容量需求"""
        future_users = self.current_users * (1 + self.growth_rate) ** years
        peak_users = future_users * self.peak_factor
        
        # 资源需求计算
        cpu_cores = max(8, int(peak_users / 100))  # 每100用户1核心
        memory_gb = max(16, int(peak_users / 50))  # 每50用户1GB内存
        storage_gb = max(500, int(future_users * 0.5))  # 每用户0.5GB存储
        
        return {
            'future_users': future_users,
            'peak_users': peak_users,
            'cpu_cores': cpu_cores,
            'memory_gb': memory_gb,
            'storage_gb': storage_gb
        }

# 使用示例
planner = CapacityPlanner()
capacity = planner.calculate_future_capacity(3)
print(f"3年后容量需求: {capacity}")
```

### 扩容方案

#### 水平扩容
```yaml
# docker-compose.scale.yml
version: '3.8'
services:
  backend:
    image: knowledge-base/backend:latest
    deploy:
      replicas: 3
    environment:
      - INSTANCE_ID=${HOSTNAME}
    
  frontend:
    image: knowledge-base/frontend:latest
    deploy:
      replicas: 2
      
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - backend
      - frontend
```

#### 垂直扩容
```bash
#!/bin/bash
# scale_up.sh - 垂直扩容脚本

# 停止服务
docker-compose down

# 更新资源限制
cat > docker-compose.override.yml << EOF
version: '3.8'
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '2.0'
          memory: 4G
          
  nebula-graphd:
    deploy:
      resources:
        limits:
          cpus: '8.0'
          memory: 16G
        reservations:
          cpus: '4.0'
          memory: 8G
EOF

# 重启服务
docker-compose up -d
```

## 版本管理

### 版本发布流程

#### 发布检查清单
- [ ] 代码审查完成
- [ ] 单元测试通过
- [ ] 集成测试通过
- [ ] 性能测试通过
- [ ] 安全扫描通过
- [ ] 文档更新完成
- [ ] 备份数据完成
- [ ] 回滚方案准备

#### 发布脚本
```bash
#!/bin/bash
# deploy.sh - 生产环境发布脚本

VERSION=$1
ENVIRONMENT=${2:-production}

if [ -z "$VERSION" ]; then
    echo "使用方法: $0 <版本号> [环境]"
    echo "示例: $0 v1.2.0 production"
    exit 1
fi

echo "开始发布版本 $VERSION 到 $ENVIRONMENT 环境"

# 1. 备份当前版本
echo "备份当前版本..."
./backup.sh

# 2. 拉取新版本代码
echo "拉取新版本代码..."
git fetch origin
git checkout $VERSION

# 3. 构建新版本
echo "构建新版本..."
docker-compose build

# 4. 数据库迁移
echo "执行数据库迁移..."
docker-compose run --rm backend python manage.py migrate

# 5. 滚动更新
echo "执行滚动更新..."
docker-compose up -d --no-deps backend
sleep 30
docker-compose up -d --no-deps frontend

# 6. 健康检查
echo "执行健康检查..."
./health_check.sh

if [ $? -eq 0 ]; then
    echo "发布成功!"
    # 发送通知
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"知识库系统版本 '$VERSION' 发布成功"}' \
        $SLACK_WEBHOOK_URL
else
    echo "发布失败，开始回滚..."
    ./rollback.sh
    exit 1
fi
```

### 回滚方案
```bash
#!/bin/bash
# rollback.sh - 回滚脚本

echo "开始回滚操作..."

# 1. 获取上一个版本
PREVIOUS_VERSION=$(git describe --tags --abbrev=0 HEAD~1)
echo "回滚到版本: $PREVIOUS_VERSION"

# 2. 停止当前服务
docker-compose down

# 3. 恢复代码版本
git checkout $PREVIOUS_VERSION

# 4. 恢复数据库
BACKUP_FILE=$(ls -t /backup/knowledge-base/database/nebula_backup_*.sql.gz | head -1)
echo "恢复数据库: $BACKUP_FILE"
./restore.sh $(basename $BACKUP_FILE .sql.gz | sed 's/nebula_backup_//')

# 5. 启动服务
docker-compose up -d

# 6. 验证回滚
./health_check.sh

echo "回滚完成"
```

---

**文档维护**: 运维团队  
**最后更新**: 2024-01-15  
**版本**: v1.0